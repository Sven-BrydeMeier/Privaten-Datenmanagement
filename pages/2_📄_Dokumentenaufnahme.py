"""
Dokumentenaufnahme - Upload, Scan und Verarbeitung von Dokumenten
"""
import streamlit as st
import io
import hashlib
from pathlib import Path
import sys
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))

from database.db import init_db, get_db, get_current_user_id
from database.models import Document, Folder, DocumentStatus, CalendarEvent, EventType, InvoiceStatus
from config.settings import DOCUMENTS_DIR, DOCUMENT_CATEGORIES
from services.encryption import get_encryption_service
from services.ocr import get_ocr_service
from services.ai_service import get_ai_service
from services.document_classifier import get_classifier
from services.search_service import get_search_service
from utils.pdf_utils import get_pdf_processor
from utils.helpers import format_currency, format_date, sanitize_filename, get_local_now
from utils.components import render_sidebar_cart

st.set_page_config(page_title="Dokumentenaufnahme", page_icon="üìÑ", layout="wide")
init_db()

# Sidebar mit Aktentasche
render_sidebar_cart()

# Debug-Modus Toggle in der Sidebar
with st.sidebar:
    st.divider()
    debug_mode = st.checkbox("üêõ Debug-Modus", value=st.session_state.get('debug_mode', False),
                             help="Zeigt detaillierte Verarbeitungsschritte an")
    st.session_state.debug_mode = debug_mode

st.title("üìÑ Dokumentenaufnahme")
st.markdown("Laden Sie Dokumente hoch oder scannen Sie sie ein")


def debug_log(message: str, level: str = "info"):
    """F√ºgt eine Debug-Nachricht zum Log hinzu"""
    if 'debug_log' not in st.session_state:
        st.session_state.debug_log = []
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    st.session_state.debug_log.append({
        'time': timestamp,
        'level': level,
        'message': message
    })


def clear_debug_log():
    """L√∂scht das Debug-Log"""
    st.session_state.debug_log = []


def show_debug_panel():
    """Zeigt das Debug-Panel an"""
    if not st.session_state.get('debug_mode', False):
        return

    if 'debug_log' not in st.session_state or not st.session_state.debug_log:
        return

    with st.expander("üêõ Debug-Log", expanded=True):
        # Log anzeigen
        for entry in st.session_state.debug_log:
            icon = "‚ÑπÔ∏è" if entry['level'] == "info" else "‚úÖ" if entry['level'] == "success" else "‚ö†Ô∏è" if entry['level'] == "warning" else "‚ùå"
            color = "gray" if entry['level'] == "info" else "green" if entry['level'] == "success" else "orange" if entry['level'] == "warning" else "red"
            st.markdown(f"<span style='color:{color}'>{icon} [{entry['time']}] {entry['message']}</span>",
                       unsafe_allow_html=True)

        if st.button("üóëÔ∏è Log l√∂schen"):
            clear_debug_log()
            st.rerun()


def calculate_content_hash(file_data: bytes) -> str:
    """Berechnet SHA-256 Hash des Dateiinhalts"""
    return hashlib.sha256(file_data).hexdigest()


def check_for_duplicate(file_data: bytes, user_id: int) -> dict | None:
    """
    Pr√ºft ob ein Dokument mit gleichem Inhalt bereits existiert.

    Returns:
        Dict mit Duplikat-Info oder None wenn kein Duplikat
    """
    content_hash = calculate_content_hash(file_data)

    with get_db() as session:
        existing = session.query(Document).filter(
            Document.user_id == user_id,
            Document.content_hash == content_hash
        ).first()

        if existing:
            # Ordnerinfo laden
            folder_name = "Kein Ordner"
            folder_path = ""
            if existing.folder_id:
                folder = session.get(Folder, existing.folder_id)
                if folder:
                    folder_name = folder.name
                    # Pfad aufbauen
                    path_parts = [folder.name]
                    parent = folder.parent_id
                    while parent:
                        parent_folder = session.get(Folder, parent)
                        if parent_folder:
                            path_parts.insert(0, parent_folder.name)
                            parent = parent_folder.parent_id
                        else:
                            break
                    folder_path = " / ".join(path_parts)

            return {
                'id': existing.id,
                'filename': existing.filename,
                'title': existing.title or existing.filename,
                'sender': existing.sender,
                'category': existing.category,
                'document_date': existing.document_date,
                'created_at': existing.created_at,
                'folder_id': existing.folder_id,
                'folder_name': folder_name,
                'folder_path': folder_path,
                'file_path': existing.file_path,
                'content_hash': content_hash
            }

    return None


def render_duplicate_comparison(new_file_data: bytes, new_filename: str, existing_doc: dict, user_id: int):
    """Zeigt Vergleichsansicht f√ºr Duplikate"""
    st.warning("‚ö†Ô∏è **M√∂gliches Duplikat erkannt!**")
    st.info(f"Ein Dokument mit identischem Inhalt existiert bereits in: **{existing_doc['folder_path']}**")

    col_new, col_existing = st.columns(2)

    with col_new:
        st.markdown("### üìÑ Neues Dokument")
        st.write(f"**Dateiname:** {new_filename}")
        st.write(f"**Gr√∂√üe:** {len(new_file_data) / 1024:.1f} KB")

        # Vorschau f√ºr neues Dokument
        if new_filename.lower().endswith('.pdf'):
            try:
                from pdf2image import convert_from_bytes
                images = convert_from_bytes(new_file_data, first_page=1, last_page=1, dpi=100)
                if images:
                    st.image(images[0], caption="Vorschau (Seite 1)", width="stretch")
            except Exception:
                st.info("PDF-Vorschau nicht verf√ºgbar")
        else:
            st.image(new_file_data, caption="Vorschau", width="stretch")

    with col_existing:
        st.markdown("### üìÅ Bestehendes Dokument")
        st.write(f"**Dateiname:** {existing_doc['filename']}")
        st.write(f"**Titel:** {existing_doc['title'] or '‚Äî'}")
        st.write(f"**Absender:** {existing_doc['sender'] or '‚Äî'}")
        st.write(f"**Kategorie:** {existing_doc['category'] or '‚Äî'}")
        st.write(f"**Datum:** {format_date(existing_doc['document_date'])}")
        st.write(f"**Hochgeladen:** {format_date(existing_doc['created_at'])}")
        st.write(f"**üìÅ Ordner:** {existing_doc['folder_path']}")

        # Vorschau f√ºr bestehendes Dokument laden
        if existing_doc['file_path']:
            try:
                encryption = get_encryption_service()
                with open(existing_doc['file_path'], 'rb') as f:
                    encrypted_data = f.read()

                with get_db() as session:
                    doc = session.get(Document, existing_doc['id'])
                    if doc and doc.encryption_iv:
                        decrypted_data = encryption.decrypt_file(encrypted_data, doc.encryption_iv, doc.filename)

                        if existing_doc['filename'].lower().endswith('.pdf'):
                            try:
                                from pdf2image import convert_from_bytes
                                images = convert_from_bytes(decrypted_data, first_page=1, last_page=1, dpi=100)
                                if images:
                                    st.image(images[0], caption="Vorschau (Seite 1)", width="stretch")
                            except Exception:
                                st.info("PDF-Vorschau nicht verf√ºgbar")
                        else:
                            st.image(decrypted_data, caption="Vorschau", width="stretch")
            except Exception as e:
                st.info(f"Vorschau nicht verf√ºgbar: {e}")

    st.divider()

    # Aktionen
    st.markdown("### Was m√∂chten Sie tun?")
    col_action1, col_action2, col_action3 = st.columns(3)

    with col_action1:
        if st.button("üö´ Nicht hochladen", use_container_width=True, help="Abbrechen, bestehendes Dokument behalten"):
            if 'duplicate_check' in st.session_state:
                del st.session_state.duplicate_check
            st.rerun()

    with col_action2:
        if st.button("üìÇ Zum bestehenden Dokument", use_container_width=True, help="Bestehendes Dokument √∂ffnen"):
            st.session_state.current_folder_id = existing_doc['folder_id']
            if 'duplicate_check' in st.session_state:
                del st.session_state.duplicate_check
            st.switch_page("pages/3_üìÅ_Dokumente.py")

    with col_action3:
        if st.button("‚úÖ Trotzdem hochladen", type="primary", use_container_width=True, help="Als neues Dokument speichern"):
            st.session_state.force_upload = True
            if 'duplicate_check' in st.session_state:
                del st.session_state.duplicate_check
            st.rerun()


# Tabs f√ºr verschiedene Upload-Optionen
tab_upload, tab_multi, tab_folder, tab_cloud, tab_process = st.tabs([
    "üì§ Einzelupload", "üìë Mehrere Dokumente", "üìÇ Ordner-Upload", "‚òÅÔ∏è Cloud-Import", "‚öôÔ∏è Verarbeitung"
])


def save_document(file_data: bytes, filename: str, user_id: int) -> Document:
    """Speichert ein Dokument verschl√ºsselt und erstellt DB-Eintrag"""
    import unicodedata

    encryption = get_encryption_service()

    # Dateiname normalisieren f√ºr konsistente Umlaut-Behandlung
    if isinstance(filename, bytes):
        try:
            filename = filename.decode('utf-8')
        except UnicodeDecodeError:
            filename = filename.decode('latin-1', errors='replace')

    # Unicode-Normalisierung (NFC) f√ºr konsistente Umlaute (√§, √∂, √º)
    filename = unicodedata.normalize('NFC', filename)

    # WICHTIG: Dateiname auf sichere L√§nge k√ºrzen
    # VARCHAR(255) in der DB, aber UTF-8-Umlaute brauchen 2 Bytes
    # Also maximal ~120 Zeichen um sicher zu sein
    if len(filename) > 150:
        name_part, ext = filename.rsplit('.', 1) if '.' in filename else (filename, '')
        # K√ºrze den Namen, behalte die Extension
        max_name_len = 150 - len(ext) - 1 if ext else 150
        name_part = name_part[:max_name_len]
        filename = f"{name_part}.{ext}" if ext else name_part

    # Content-Hash berechnen
    content_hash = calculate_content_hash(file_data)

    # Datei verschl√ºsseln (verwendet intern auch NFC-Normalisierung)
    encrypted_data, nonce = encryption.encrypt_file(file_data, filename)

    # Sicheren Dateinamen generieren (beh√§lt Umlaute bei)
    safe_filename = sanitize_filename(filename)
    timestamp = get_local_now().strftime("%Y%m%d_%H%M%S")
    stored_filename = f"{timestamp}_{safe_filename}.enc"

    # Auch den gespeicherten Pfad auf sichere L√§nge begrenzen
    if len(stored_filename) > 200:
        # K√ºrze den safe_filename wenn n√∂tig
        max_safe = 200 - len(timestamp) - 6  # 6 f√ºr "_.enc"
        safe_filename = safe_filename[:max_safe]
        stored_filename = f"{timestamp}_{safe_filename}.enc"

    file_path = DOCUMENTS_DIR / stored_filename

    # Verschl√ºsselte Datei speichern
    with open(file_path, 'wb') as f:
        f.write(encrypted_data)

    # Mime-Type bestimmen
    mime_type = "application/pdf" if filename.lower().endswith('.pdf') else "image/jpeg"
    if filename.lower().endswith('.png'):
        mime_type = "image/png"

    # Posteingang-Ordner finden
    with get_db() as session:
        inbox = session.query(Folder).filter(
            Folder.user_id == user_id,
            Folder.name == "Posteingang"
        ).first()

        # Dokument in DB erstellen
        document = Document(
            user_id=user_id,
            folder_id=inbox.id if inbox else None,
            filename=filename[:250],  # Sicherheits-Limit f√ºr DB
            file_path=str(file_path),
            file_size=len(file_data),
            mime_type=mime_type,
            is_encrypted=True,
            encryption_iv=nonce,
            content_hash=content_hash,
            status=DocumentStatus.PENDING
        )
        session.add(document)
        session.commit()

        return document.id


def process_document(document_id: int, file_data: bytes, user_id: int) -> dict:
    """Verarbeitet ein Dokument mit OCR und KI. Gibt Info √ºber zugewiesenen Ordner zur√ºck."""
    is_debug = st.session_state.get('debug_mode', False)

    if is_debug:
        debug_log(f"‚ñ∂Ô∏è Starte Verarbeitung f√ºr Dokument ID: {document_id}", "info")
        debug_log(f"üì¶ Dateigr√∂√üe: {len(file_data)} Bytes", "info")

    try:
        if is_debug:
            debug_log("üîß Initialisiere Services...", "info")
        ocr = get_ocr_service()
        ai = get_ai_service()
        classifier = get_classifier(user_id)
        search = get_search_service(user_id)
        if is_debug:
            debug_log("‚úÖ Services initialisiert", "success")
    except Exception as e:
        if is_debug:
            debug_log(f"‚ùå Service-Initialisierung fehlgeschlagen: {str(e)[:200]}", "error")
        return {'error': f"Service-Init fehlgeschlagen: {str(e)[:100]}"}

    result = {
        'folder_name': None,
        'folder_path': None,
        'folder_created': False,
        'sender': None,
        'virtual_folders': [],
        'property_name': None,
        'category': None,
        'subcategory': None
    }

    try:
        with get_db() as session:
            if is_debug:
                debug_log("üîç Lade Dokument aus Datenbank...", "info")

            document = session.get(Document, document_id)
            if not document:
                if is_debug:
                    debug_log(f"‚ùå Dokument {document_id} nicht gefunden!", "error")
                return result

            if is_debug:
                debug_log(f"üìÑ Dokument geladen: {document.filename[:50]}...", "success")
                debug_log(f"üìã MIME-Type: {document.mime_type}", "info")

            document.status = DocumentStatus.PROCESSING
            session.commit()

            try:
                # OCR durchf√ºhren
                full_text = ""
                confidence = 0.0
                ocr_error = None

                if is_debug:
                    debug_log("üî§ Starte OCR-Extraktion...", "info")

                if document.mime_type == "application/pdf":
                    if is_debug:
                        debug_log("üìë PDF erkannt - extrahiere Text...", "info")
                    try:
                        results = ocr.extract_text_from_pdf(file_data)
                        if results:
                            full_text = "\n\n".join(text for text, _ in results)
                            confidence = sum(conf for _, conf in results) / len(results)
                            if is_debug:
                                debug_log(f"‚úÖ OCR erfolgreich: {len(full_text)} Zeichen, Konfidenz: {confidence:.2f}", "success")
                        else:
                            if is_debug:
                                debug_log("‚ö†Ô∏è Kein Text extrahiert (m√∂glicherweise Bild-PDF)", "warning")
                    except Exception as ocr_err:
                        ocr_error = str(ocr_err)[:200]
                        if is_debug:
                            debug_log(f"‚ö†Ô∏è PDF-OCR Fehler (wird √ºbersprungen): {ocr_error}", "warning")
                        # NICHT abbrechen - Dokument trotzdem speichern
                        full_text = f"[OCR-Fehler: {ocr_error}]"
                else:
                    # Bild
                    if is_debug:
                        debug_log("üñºÔ∏è Bild erkannt - starte Bild-OCR...", "info")
                    try:
                        from PIL import Image
                        image = Image.open(io.BytesIO(file_data))
                        if is_debug:
                            debug_log(f"üìê Bildgr√∂√üe: {image.size}", "info")
                        full_text, confidence = ocr.extract_text_from_image(image)
                        if is_debug:
                            debug_log(f"‚úÖ Bild-OCR erfolgreich: {len(full_text)} Zeichen", "success")
                    except Exception as img_err:
                        ocr_error = str(img_err)[:200]
                        if is_debug:
                            debug_log(f"‚ö†Ô∏è Bild-OCR Fehler (wird √ºbersprungen): {ocr_error}", "warning")
                        # NICHT abbrechen - Dokument trotzdem speichern
                        full_text = f"[OCR-Fehler: {ocr_error}]"

                document.ocr_text = full_text
                document.ocr_confidence = confidence
                if ocr_error:
                    document.processing_notes = f"OCR-Fehler: {ocr_error}"

                # Metadaten extrahieren
                if is_debug:
                    debug_log("üìä Extrahiere Metadaten aus Text...", "info")

                try:
                    metadata = ocr.extract_metadata(full_text)
                    if is_debug:
                        debug_log(f"‚úÖ Metadaten extrahiert: {len(metadata.get('dates', []))} Daten, {len(metadata.get('amounts', []))} Betr√§ge", "success")
                except Exception as meta_err:
                    if is_debug:
                        debug_log(f"‚ö†Ô∏è Metadaten-Extraktion Fehler: {str(meta_err)[:200]}", "warning")
                    metadata = {}

                # Daten zuweisen
                if metadata.get('dates'):
                    document.document_date = metadata['dates'][0]

                if metadata.get('amounts'):
                    document.invoice_amount = max(metadata['amounts'])

                if metadata.get('ibans'):
                    document.iban = metadata['ibans'][0]

                if metadata.get('contract_numbers'):
                    document.contract_number = metadata['contract_numbers'][0]

                # KI-basierte Klassifikation (wenn verf√ºgbar)
                if is_debug:
                    debug_log(f"ü§ñ KI verf√ºgbar: {ai.any_ai_available}", "info")

                if ai.any_ai_available:
                    if is_debug:
                        debug_log("üß† Starte KI-Analyse...", "info")
                    try:
                        structured_data = ai.extract_structured_data(full_text)
                        if is_debug:
                            debug_log(f"‚úÖ KI-Analyse abgeschlossen", "success")

                        # Absender-Informationen
                        if structured_data.get('sender'):
                            document.sender = structured_data['sender']
                            result['sender'] = structured_data['sender']
                        if structured_data.get('sender_address'):
                            document.sender_address = structured_data['sender_address']

                        # Betreff und Kategorie
                        if structured_data.get('subject'):
                            document.subject = structured_data['subject']
                            document.title = structured_data['subject']
                        if structured_data.get('category'):
                            document.category = structured_data['category']

                        # Zusammenfassung
                        if structured_data.get('summary'):
                            document.ai_summary = structured_data['summary']

                        # Referenznummern
                        if structured_data.get('reference_number'):
                            document.reference_number = structured_data['reference_number']
                        if structured_data.get('customer_number'):
                            document.customer_number = structured_data['customer_number']
                        if structured_data.get('insurance_number'):
                            document.insurance_number = structured_data['insurance_number']
                        if structured_data.get('processing_number'):
                            document.processing_number = structured_data['processing_number']
                        if structured_data.get('contract_number') and not document.contract_number:
                            document.contract_number = structured_data['contract_number']

                        # Rechnungsnummer
                        if structured_data.get('invoice_number'):
                            document.invoice_number = structured_data['invoice_number']

                        # Finanzinformationen
                        if structured_data.get('invoice_amount'):
                            document.invoice_amount = float(structured_data['invoice_amount'])
                        if structured_data.get('invoice_due_date'):
                            from utils.helpers import parse_date_string
                            due_date = parse_date_string(structured_data['invoice_due_date'])
                            if due_date:
                                document.invoice_due_date = due_date
                        if structured_data.get('iban') and not document.iban:
                            document.iban = structured_data['iban']
                        if structured_data.get('bic'):
                            document.bic = structured_data['bic']
                        if structured_data.get('bank_name'):
                            document.bank_name = structured_data['bank_name']

                        # Automatische Rechnungserkennung - als OFFEN markieren
                        is_invoice = structured_data.get('is_invoice', False)
                        if is_invoice or structured_data.get('category') in ['Rechnung', 'Mahnung']:
                            if document.invoice_amount and document.invoice_amount > 0:
                                document.invoice_status = InvoiceStatus.OPEN

                    except Exception as e:
                        if is_debug:
                            debug_log(f"‚ö†Ô∏è KI-Analyse fehlgeschlagen: {str(e)[:200]}", "warning")
                        st.warning(f"KI-Analyse teilweise fehlgeschlagen: {e}")

                # ============================================================
                # GELERNTE FELDPOSITIONEN ANWENDEN (Field Learning)
                # ============================================================
                if not document.sender or document.sender.strip() == "":
                    if is_debug:
                        debug_log("üéØ Pr√ºfe gelernte Feldpositionen...", "info")
                    try:
                        from services.field_learning_service import get_field_learning_service
                        field_service = get_field_learning_service(user_id)

                        # Passendes Template suchen
                        template = field_service.find_matching_template(full_text, document.sender)

                        if template:
                            if is_debug:
                                debug_log(f"‚úÖ Template gefunden: {template['name']} (Score: {template.get('score', 0):.0%})", "success")

                            # Dokument als Bild laden f√ºr Feldextraktion
                            doc_image = None
                            if filename.lower().endswith('.pdf'):
                                try:
                                    from pdf2image import convert_from_bytes
                                    images = convert_from_bytes(file_data, first_page=1, last_page=1, dpi=150)
                                    if images:
                                        doc_image = images[0]
                                except:
                                    pass
                            else:
                                from PIL import Image
                                doc_image = Image.open(io.BytesIO(file_data))

                            if doc_image:
                                # Felder extrahieren
                                extracted = field_service.extract_fields_with_template(doc_image, template)

                                if extracted:
                                    if is_debug:
                                        debug_log(f"üìã Felder extrahiert: {list(extracted.keys())}", "success")

                                    # Felder auf Dokument anwenden
                                    if 'sender' in extracted and not document.sender:
                                        document.sender = extracted['sender']
                                        result['sender'] = extracted['sender']
                                    if 'amount' in extracted and not document.invoice_amount:
                                        try:
                                            document.invoice_amount = float(extracted['amount'].replace(',', '.'))
                                        except:
                                            pass
                                    if 'iban' in extracted and not document.iban:
                                        document.iban = extracted['iban'].replace(' ', '')
                                    if 'customer_number' in extracted and not document.customer_number:
                                        document.customer_number = extracted['customer_number']
                                    if 'invoice_number' in extracted and not document.invoice_number:
                                        document.invoice_number = extracted['invoice_number']
                                    if 'due_date' in extracted and not document.invoice_due_date:
                                        parsed = field_service._parse_date(extracted['due_date'])
                                        if parsed:
                                            document.invoice_due_date = parsed
                        else:
                            if is_debug:
                                debug_log("‚ÑπÔ∏è Kein passendes Template gefunden", "info")

                    except Exception as fl_error:
                        if is_debug:
                            debug_log(f"‚ö†Ô∏è Field Learning Fehler: {str(fl_error)[:200]}", "warning")

                # ============================================================
                # INTELLIGENTE KLASSIFIKATION MIT KI-UNTERST√úTZUNG
                # ============================================================
                if is_debug:
                    debug_log("üìÇ Starte Dokumenten-Klassifikation...", "info")

                try:
                    classification = classifier.classify_with_ai(full_text, metadata)
                    if is_debug:
                        debug_log(f"‚úÖ Klassifikation abgeschlossen: Kategorie={classification.get('category')}, Ordner={classification.get('primary_folder_path')}", "success")
                except Exception as class_error:
                    if is_debug:
                        debug_log(f"‚ùå Klassifikation fehlgeschlagen: {str(class_error)[:200]}", "error")
                    # Bei Klassifikationsfehler: Standardwerte verwenden
                    classification = {
                        'category': document.category or 'Sonstiges',
                        'subcategory': None,
                        'primary_folder_id': None,
                        'primary_folder_path': None,
                        'virtual_folder_ids': [],
                        'property_id': None,
                        'detected_address': None,
                        'confidence': 0.0
                    }

                # Kategorie und Unterkategorie zuweisen
                if classification.get('category'):
                    document.category = classification['category']
                    result['category'] = classification['category']
                if classification.get('subcategory'):
                    result['subcategory'] = classification['subcategory']

                # Extrahierte Adresse speichern (f√ºr Immobilien-Zuordnung)
                if classification.get('detected_address'):
                    document.property_address = classification['detected_address']

                # Immobilien-Zuordnung
                if classification.get('property_id'):
                    document.property_id = classification['property_id']
                    # Property-Name f√ºr Anzeige laden
                    from database.models import Property
                    prop = session.get(Property, classification['property_id'])
                    if prop:
                        result['property_name'] = prop.name or prop.full_address

                # Ordnerzuweisung aus Klassifikation
                assigned_folder_name = None
                folder_created = False
                folder_id = classification.get('primary_folder_id')
                folder_path = classification.get('primary_folder_path')

                # Pr√ºfen ob ein intelligenter Ordner gefunden wurde (nicht nur Posteingang)
                if folder_id:
                    folder = session.get(Folder, folder_id)
                    if folder and folder.name != 'Posteingang':
                        # Intelligenter Ordner gefunden
                        document.folder_id = folder_id
                        assigned_folder_name = folder.name
                        result['folder_path'] = folder_path
                        # Ordner wurde m√∂glicherweise neu erstellt
                        folder_created = classification.get('confidence', 0) > 0.7
                    else:
                        folder_id = None  # Posteingang z√§hlt nicht als "gefunden"

                # Wenn kein passender Ordner gefunden, Ordner nach Absender erstellen
                if not folder_id and document.sender:
                    sender_name = document.sender.strip()
                    if sender_name:
                        # Pr√ºfen ob Absender-Ordner bereits existiert
                        existing_folder = session.query(Folder).filter(
                            Folder.user_id == user_id,
                            Folder.name == sender_name
                        ).first()

                        if existing_folder:
                            document.folder_id = existing_folder.id
                            assigned_folder_name = existing_folder.name
                        else:
                            # Neuen Ordner nach Absender erstellen
                            new_folder = Folder(
                                user_id=user_id,
                                name=sender_name,
                                description=f"Automatisch erstellt f√ºr Dokumente von {sender_name}",
                                color="#607D8B"  # Grau-Blau f√ºr auto-erstellte Ordner
                            )
                            session.add(new_folder)
                            session.flush()  # ID generieren
                            document.folder_id = new_folder.id
                            assigned_folder_name = sender_name
                            folder_created = True

                result['folder_name'] = assigned_folder_name
                result['folder_created'] = folder_created

                # ============================================================
                # VIRTUELLE ORDNER-ZUORDNUNG (Dokument in mehreren Ordnern)
                # ============================================================
                virtual_folder_ids = classification.get('virtual_folder_ids', [])
                if virtual_folder_ids:
                    try:
                        # Virtuelle Ordner zuweisen
                        classifier.assign_to_virtual_folders(document_id, virtual_folder_ids)
                        # Namen der virtuellen Ordner f√ºr Anzeige sammeln
                        for vf_id in virtual_folder_ids:
                            vf = session.get(Folder, vf_id)
                            if vf:
                                result['virtual_folders'].append(vf.name)
                    except Exception:
                        pass  # Fehler bei virtuellen Ordnern ignorieren

                # Fristen erkennen und Kalendereintrag erstellen
                for deadline in metadata.get('deadlines', []):
                    deadline_date = None
                    # Versuche Datum zu parsen
                    from utils.helpers import parse_german_date
                    deadline_date = parse_german_date(deadline['date_str'])

                    if deadline_date:
                        event = CalendarEvent(
                            user_id=user_id,
                            document_id=document.id,
                            title=f"Frist: {document.title or document.filename}",
                            description=f"Automatisch erkannte Frist aus Dokument",
                            event_type=EventType.DEADLINE,
                            start_date=deadline_date,
                            all_day=True
                        )
                        session.add(event)

                # Suchindex aktualisieren
                if is_debug:
                    debug_log("üîç Aktualisiere Suchindex...", "info")
                search.index_document(document.id, {
                    'title': document.title or document.filename,
                    'content': full_text,
                    'sender': document.sender or '',
                    'category': document.category or '',
                    'folder_id': document.folder_id,
                    'document_date': document.document_date,
                    'amounts': metadata.get('amounts', []),
                    'ibans': metadata.get('ibans', []),
                    'contract_numbers': metadata.get('contract_numbers', []),
                    'created_at': document.created_at
                })

                if is_debug:
                    debug_log("üíæ Speichere Dokument...", "info")
                document.status = DocumentStatus.COMPLETED
                session.commit()

                if is_debug:
                    debug_log("‚úÖ Verarbeitung abgeschlossen!", "success")
                return result

            except Exception as e:
                if is_debug:
                    import traceback
                    debug_log(f"‚ùå FEHLER: {str(e)[:300]}", "error")
                    debug_log(f"üìç Traceback: {traceback.format_exc()[-500:]}", "error")
                document.status = DocumentStatus.ERROR
                document.processing_error = str(e)[:500]  # Begrenze Fehlerl√§nge
                try:
                    session.commit()
                except Exception:
                    pass  # Commit-Fehler ignorieren
                # NICHT raise - stattdessen Fehler protokollieren und weitermachen
                result['error'] = str(e)[:200]
                return result

    except Exception as outer_err:
        if is_debug:
            import traceback
            debug_log(f"‚ùå √ÑUSSERER FEHLER: {str(outer_err)[:300]}", "error")
            debug_log(f"üìç Traceback: {traceback.format_exc()[-500:]}", "error")
        return {'error': str(outer_err)[:200]}

    return result


with tab_upload:
    st.subheader("Einzelnes Dokument hochladen")

    uploaded_file = st.file_uploader(
        "PDF oder Bild ausw√§hlen",
        type=['pdf', 'jpg', 'jpeg', 'png'],
        help="Unterst√ºtzte Formate: PDF, JPG, PNG"
    )

    if uploaded_file:
        file_data = uploaded_file.read()
        uploaded_file.seek(0)  # Reset f√ºr sp√§tere Verwendung

        # Pr√ºfe auf Duplikat (au√üer bei force_upload)
        user_id = get_current_user_id()
        force_upload = st.session_state.get('force_upload', False)

        if not force_upload:
            duplicate = check_for_duplicate(file_data, user_id)
            if duplicate:
                render_duplicate_comparison(file_data, uploaded_file.name, duplicate, user_id)
                st.stop()  # Stoppe hier, zeige nur Duplikat-Vergleich

        # Kein Duplikat oder force_upload - normale Ansicht
        if force_upload:
            st.info("üìÑ Dokument wird trotz Duplikat hochgeladen...")
            st.session_state.force_upload = False  # Reset

        st.success(f"Datei: {uploaded_file.name} ({uploaded_file.size / 1024:.1f} KB)")

        # Vorschau
        if uploaded_file.type == "application/pdf":
            st.info("PDF-Vorschau wird nach Verarbeitung verf√ºgbar")
        else:
            st.image(uploaded_file, width=400, caption="Vorschau")

        col1, col2 = st.columns(2)

        with col1:
            process_now = st.checkbox("Sofort verarbeiten (OCR & KI)", value=True)

        with col2:
            if st.button("üì• Hochladen", type="primary"):
                with st.spinner("Speichere Dokument..."):
                    doc_id = save_document(file_data, uploaded_file.name, user_id)

                if process_now:
                    # Debug-Log vor Start l√∂schen
                    if st.session_state.get('debug_mode', False):
                        clear_debug_log()

                    with st.spinner("Verarbeite Dokument (OCR & Analyse)..."):
                        try:
                            process_result = process_document(doc_id, file_data, user_id)

                            # Debug-Panel anzeigen
                            show_debug_panel()

                            # Fehler anzeigen falls vorhanden
                            if process_result.get('error'):
                                st.error(f"‚ö†Ô∏è Fehler bei Verarbeitung: {process_result['error']}")
                            else:
                                st.success("Dokument erfolgreich verarbeitet!")

                            # Ordnerzuweisung anzeigen
                            if process_result.get('folder_name'):
                                folder_info = process_result['folder_name']
                                if process_result.get('folder_path'):
                                    folder_info = process_result['folder_path']
                                if process_result.get('folder_created'):
                                    st.info(f"üìÅ **Neuer Ordner erstellt:** '{folder_info}'")
                                else:
                                    st.info(f"üìÅ **Eingeordnet in:** '{folder_info}'")
                            else:
                                st.warning("üìÅ Kein passender Ordner gefunden. Dokument bleibt im Posteingang.")

                            # Kategorie und Unterkategorie anzeigen
                            if process_result.get('subcategory'):
                                st.info(f"üè∑Ô∏è **Kategorie:** {process_result['category']} / {process_result['subcategory']}")

                            # Immobilien-Zuordnung anzeigen
                            if process_result.get('property_name'):
                                st.success(f"üè† **Immobilie erkannt:** {process_result['property_name']}")

                            # Virtuelle Ordner-Zuordnungen anzeigen
                            if process_result.get('virtual_folders'):
                                vf_list = ", ".join(process_result['virtual_folders'])
                                st.info(f"üìÇ **Auch verf√ºgbar in:** {vf_list}")

                            # Ergebnisse anzeigen
                            with get_db() as session:
                                doc = session.get(Document, doc_id)
                                if doc:
                                    st.markdown("---")
                                    st.markdown("## üìã Extrahierte Dokumentdaten")

                                    # Zusammenfassung (wenn vorhanden)
                                    if doc.ai_summary:
                                        st.info(f"**Zusammenfassung:** {doc.ai_summary}")

                                    # Drei-Spalten-Layout f√ºr Metadaten
                                    col_sender, col_refs, col_finance = st.columns(3)

                                    with col_sender:
                                        st.markdown("### üì§ Absender")
                                        st.write(f"**Name:** {doc.sender or '‚Äî'}")
                                        if doc.sender_address:
                                            st.write(f"**Adresse:** {doc.sender_address}")
                                        st.write(f"**Kategorie:** {doc.category or '‚Äî'}")
                                        st.write(f"**Datum:** {format_date(doc.document_date)}")

                                    with col_refs:
                                        st.markdown("### üî¢ Referenznummern")
                                        if doc.reference_number:
                                            st.write(f"**Aktenzeichen:** {doc.reference_number}")
                                        if doc.customer_number:
                                            st.write(f"**Kundennummer:** {doc.customer_number}")
                                        if getattr(doc, 'invoice_number', None):
                                            st.write(f"**Rechnungsnr:** {doc.invoice_number}")
                                        if doc.insurance_number:
                                            st.write(f"**Vers.-Nr:** {doc.insurance_number}")
                                        if doc.processing_number:
                                            st.write(f"**Bearbeitungsnr:** {doc.processing_number}")
                                        if doc.contract_number:
                                            st.write(f"**Vertragsnr:** {doc.contract_number}")
                                        if not any([doc.reference_number, doc.customer_number,
                                                   getattr(doc, 'invoice_number', None),
                                                   doc.insurance_number, doc.processing_number,
                                                   doc.contract_number]):
                                            st.write("‚Äî")

                                    with col_finance:
                                        st.markdown("### üí∞ Finanzdaten")
                                        # Rechnungsstatus anzeigen
                                        if doc.invoice_status == InvoiceStatus.OPEN:
                                            st.error("üî¥ Rechnung OFFEN")
                                        if doc.invoice_amount:
                                            st.write(f"**Betrag:** {format_currency(doc.invoice_amount)}")
                                        if doc.invoice_due_date:
                                            st.write(f"**F√§llig bis:** {format_date(doc.invoice_due_date)}")
                                        if doc.iban:
                                            st.write(f"**IBAN:** {doc.iban}")
                                        if doc.bic:
                                            st.write(f"**BIC:** {doc.bic}")
                                        if getattr(doc, 'bank_name', None):
                                            st.write(f"**Bank:** {doc.bank_name}")
                                        if not any([doc.invoice_amount, doc.iban]):
                                            st.write("‚Äî")

                                    # Link zum Dokument
                                    st.markdown("---")
                                    if st.button("üìÇ Dokument in Ordner √∂ffnen"):
                                        st.session_state.view_document_id = doc_id
                                        st.switch_page("pages/3_üìÅ_Dokumente.py")
                        except Exception as e:
                            st.error(f"Verarbeitungsfehler: {e}")
                else:
                    st.success("Dokument gespeichert! Kann sp√§ter verarbeitet werden.")


with tab_multi:
    st.subheader("Mehrere Dokumente in einer PDF")
    st.markdown("""
    Laden Sie eine PDF mit mehreren Dokumenten hoch. Die App erkennt automatisch:
    - **Trennseiten** (wei√üe Seite mit dem Wort "Trennseite")
    - **Layoutwechsel** (unterschiedliche Dokumenttypen)
    """)

    multi_file = st.file_uploader(
        "PDF mit mehreren Dokumenten",
        type=['pdf'],
        key="multi_upload",
        help="PDF mit mehreren gescannten Dokumenten"
    )

    if multi_file:
        pdf_processor = get_pdf_processor()
        file_data = multi_file.read()

        page_count = pdf_processor.get_page_count(file_data)
        st.info(f"PDF enth√§lt {page_count} Seiten")

        col1, col2 = st.columns(2)

        with col1:
            auto_detect = st.checkbox("Automatische Dokumenttrennung", value=True)

        with col2:
            manual_pages = st.text_input(
                "Manuelle Seitenbereiche (z.B. 1-3,4-6,7-10)",
                disabled=auto_detect,
                help="Kommagetrennte Seitenbereiche"
            )

        if st.button("üìë Dokumente trennen und verarbeiten", type="primary"):
            user_id = get_current_user_id()

            with st.spinner("Analysiere PDF..."):
                if auto_detect:
                    # Neue text-basierte Erkennung mit automatischer Trennseiten-Entfernung
                    boundaries, separator_pages = pdf_processor.detect_document_boundaries(file_data)

                    if separator_pages:
                        st.info(f"üîç {len(separator_pages)} Trennseite(n) erkannt auf Seite(n): {[s+1 for s in separator_pages]}")
                        st.write(f"Dokumentgrenzen: Seiten {[b+1 for b in boundaries]}")
                    else:
                        st.write(f"Erkannte Dokumentgrenzen: Seiten {[b+1 for b in boundaries]}")

                    # Automatisch trennen und Trennseiten entfernen
                    split_pdfs = pdf_processor.split_and_remove_separators(file_data)
                else:
                    # Manuelle Bereiche parsen
                    page_ranges = []
                    for range_str in manual_pages.split(','):
                        if '-' in range_str:
                            start, end = range_str.strip().split('-')
                            page_ranges.append((int(start) - 1, int(end)))
                        else:
                            page_ranges.append((int(range_str.strip()) - 1, int(range_str.strip())))

                    split_pdfs = pdf_processor.split_pdf(file_data, page_ranges)

            st.write(f"Trenne in {len(split_pdfs)} Dokumente...")

            # Jedes Teildokument verarbeiten
            progress = st.progress(0)
            processed_docs = []

            for i, pdf_data in enumerate(split_pdfs):
                progress.progress((i + 1) / len(split_pdfs))
                filename = f"{multi_file.name.rsplit('.', 1)[0]}_Teil{i+1}.pdf"

                with st.spinner(f"Verarbeite Dokument {i+1}/{len(split_pdfs)}..."):
                    doc_id = save_document(pdf_data, filename, user_id)
                    try:
                        result = process_document(doc_id, pdf_data, user_id)
                        folder_info = ""
                        if result.get('folder_name'):
                            if result.get('folder_created'):
                                folder_info = f" ‚Üí üìÅ Neuer Ordner: '{result['folder_name']}'"
                            else:
                                folder_info = f" ‚Üí üìÅ '{result['folder_name']}'"
                        else:
                            folder_info = " ‚Üí üìÅ Posteingang"
                        st.success(f"‚úì Dokument {i+1} verarbeitet{folder_info}")
                        processed_docs.append({'num': i+1, 'folder': result.get('folder_name') or 'Posteingang', 'created': result.get('folder_created', False)})
                    except Exception as e:
                        st.warning(f"‚ö† Dokument {i+1}: {e}")

            st.success(f"Alle {len(split_pdfs)} Dokumente wurden verarbeitet!")

            # Zusammenfassung der Ordnerzuweisungen
            if processed_docs:
                st.markdown("### üìÅ Ordnerzuweisungen")
                for doc_info in processed_docs:
                    if doc_info['created']:
                        st.write(f"- Dokument {doc_info['num']}: **{doc_info['folder']}** *(neu erstellt)*")
                    else:
                        st.write(f"- Dokument {doc_info['num']}: **{doc_info['folder']}**")


with tab_folder:
    st.subheader("üìÇ Ordner-Upload")
    st.markdown("Laden Sie einen kompletten Ordner mit Unterordnern hoch.")

    user_id = get_current_user_id()

    import base64
    import json

    # Option 1: Mehrere Dateien ausw√§hlen
    st.markdown("### üìÑ Mehrere Dateien hochladen")
    st.info("üí° W√§hlen Sie alle Dateien eines Ordners aus (im Datei-Dialog: **Strg+A** zum Ausw√§hlen aller Dateien)")

    folder_files = st.file_uploader(
        "Dateien ausw√§hlen",
        type=['pdf', 'jpg', 'jpeg', 'png', 'gif', 'doc', 'docx', 'xls', 'xlsx', 'txt'],
        accept_multiple_files=True,
        key="multi_file_upload",
        help="Halten Sie Strg gedr√ºckt um mehrere Dateien auszuw√§hlen, oder Strg+A f√ºr alle"
    )

    if folder_files and len(folder_files) > 0:
        st.success(f"‚úÖ **{len(folder_files)} Dateien** ausgew√§hlt")

        # Optionen
        col_opt1, col_opt2 = st.columns(2)
        with col_opt1:
            # Zielordner ausw√§hlen
            with get_db() as session:
                folders_db = session.query(Folder).filter(
                    Folder.user_id == user_id
                ).order_by(Folder.name).all()
                folder_options = {"__posteingang__": "üì• Posteingang (Standard)"}
                folder_options.update({str(f.id): f"üìÅ {f.name}" for f in folders_db})

            target_folder = st.selectbox(
                "Zielordner",
                options=list(folder_options.keys()),
                format_func=lambda x: folder_options.get(x, "Posteingang"),
                key="multi_file_target"
            )
        with col_opt2:
            process_multi = st.checkbox("Mit OCR verarbeiten", value=True, key="process_multi_files")

        if st.button("üì• Dateien importieren", type="primary", key="import_multi_files"):
            progress_bar = st.progress(0, text="Starte Import...")
            imported = 0
            errors = 0

            target_id = None if target_folder == "__posteingang__" else int(target_folder)

            for idx, file in enumerate(folder_files):
                progress_bar.progress((idx + 1) / len(folder_files), text=f"Importiere {idx + 1}/{len(folder_files)}: {file.name[:30]}...")

                try:
                    file_data = file.read()
                    doc_id = save_document(file_data, file.name, user_id)

                    # Zielordner setzen
                    if target_id:
                        with get_db() as session:
                            doc = session.get(Document, doc_id)
                            if doc:
                                doc.folder_id = target_id
                                session.commit()

                    # OCR verarbeiten
                    if process_multi:
                        try:
                            process_document(doc_id, file_data, user_id)
                        except Exception as proc_err:
                            st.toast(f"‚ö†Ô∏è Verarbeitung von {file.name}: {str(proc_err)[:50]}")

                    imported += 1

                except Exception as e:
                    errors += 1
                    st.warning(f"‚ö†Ô∏è Fehler bei {file.name}: {str(e)[:100]}")

            progress_bar.progress(1.0, text="‚úÖ Import abgeschlossen!")
            st.success(f"‚úÖ **{imported} Dateien** erfolgreich importiert!")
            if errors > 0:
                st.warning(f"‚ö†Ô∏è {errors} Fehler beim Import")

    # Option 2: ZIP-Upload f√ºr Ordnerstruktur
    st.markdown("---")
    st.markdown("### üì¶ ZIP-Archiv mit Ordnerstruktur")
    st.info("üí° Um die **Unterordner-Struktur zu erhalten**: Ordner als ZIP komprimieren und hier hochladen.")

    zip_file = st.file_uploader(
        "ZIP-Datei mit Ordnerstruktur",
        type=['zip'],
        key="folder_zip_upload",
        help="ZIP-Archiv mit Dokumenten und Unterordnern"
    )

    if zip_file:
        import zipfile
        from io import BytesIO

        user_id = get_current_user_id()

        # ZIP-Inhalt analysieren
        try:
            zip_buffer = BytesIO(zip_file.read())
            with zipfile.ZipFile(zip_buffer, 'r') as zf:
                # Alle Dateien im ZIP auflisten
                # Dekodiere Dateinamen korrekt (ZIP kann CP437 oder UTF-8 verwenden)
                def decode_zip_filename(name):
                    """Dekodiert ZIP-Dateinamen mit Umlaut-Unterst√ºtzung"""
                    import unicodedata
                    try:
                        # Versuche UTF-8 (moderne ZIPs)
                        if isinstance(name, bytes):
                            decoded = name.decode('utf-8')
                        else:
                            decoded = name
                        # Normalisiere Unicode f√ºr konsistente Umlaute
                        return unicodedata.normalize('NFC', decoded)
                    except UnicodeDecodeError:
                        try:
                            # Fallback: CP437 (alte ZIP-Kodierung)
                            return name.decode('cp437')
                        except (UnicodeDecodeError, AttributeError):
                            try:
                                # Weiterer Fallback: Latin-1
                                return name.decode('latin-1') if isinstance(name, bytes) else name
                            except:
                                return str(name)

                all_files = [decode_zip_filename(f) for f in zf.namelist() if not f.endswith('/')]

                # Nur unterst√ºtzte Dateitypen
                supported_ext = ['.pdf', '.jpg', '.jpeg', '.png', '.gif', '.doc', '.docx', '.xls', '.xlsx', '.txt']
                valid_files = [f for f in all_files if any(f.lower().endswith(ext) for ext in supported_ext)]

                # Ordnerstruktur anzeigen
                folders = set()
                for f in valid_files:
                    parts = f.split('/')
                    if len(parts) > 1:
                        folders.add('/'.join(parts[:-1]))

                st.success(f"‚úÖ ZIP-Datei erkannt: **{len(valid_files)} Dokumente** in **{len(folders)} Ordnern**")

                if folders:
                    with st.expander("üìÅ Gefundene Ordnerstruktur", expanded=False):
                        for folder in sorted(folders):
                            file_count = len([f for f in valid_files if f.startswith(folder + '/')])
                            st.write(f"üìÇ `{folder}` ({file_count} Dateien)")

                # Verarbeitungsoptionen
                col1, col2 = st.columns(2)
                with col1:
                    preserve_structure = st.checkbox("Ordnerstruktur in App √ºbernehmen", value=True,
                                                    help="Erstellt die Ordner automatisch in der App")
                with col2:
                    process_docs = st.checkbox("Dokumente sofort verarbeiten (OCR)", value=True)

                if st.button("üì• Ordner importieren", type="primary", key="import_zip"):
                    progress_bar = st.progress(0, text="Starte Import...")
                    status_text = st.empty()

                    imported_count = 0
                    error_count = 0
                    created_folders = {}

                    for idx, file_path in enumerate(valid_files):
                        progress = (idx + 1) / len(valid_files)
                        progress_bar.progress(progress, text=f"Importiere {idx + 1}/{len(valid_files)}...")

                        filename = file_path.split('/')[-1]
                        folder_path = '/'.join(file_path.split('/')[:-1]) if '/' in file_path else ""

                        status_text.markdown(f"üìÑ **{filename}**" + (f" (aus `{folder_path}`)" if folder_path else ""))

                        try:
                            # Datei aus ZIP extrahieren
                            file_data = zf.read(file_path)

                            # Ordner erstellen wenn n√∂tig
                            target_folder_id = None
                            if preserve_structure and folder_path:
                                if folder_path not in created_folders:
                                    # Ordnerstruktur erstellen
                                    with get_db() as session:
                                        parent_id = None
                                        for part in folder_path.split('/'):
                                            if not part:
                                                continue
                                            # Pr√ºfen ob Ordner existiert
                                            existing = session.query(Folder).filter(
                                                Folder.user_id == user_id,
                                                Folder.name == part,
                                                Folder.parent_id == parent_id
                                            ).first()

                                            if existing:
                                                parent_id = existing.id
                                            else:
                                                # Neuen Ordner erstellen
                                                new_folder = Folder(
                                                    user_id=user_id,
                                                    name=part,
                                                    parent_id=parent_id,
                                                    color="#4CAF50"
                                                )
                                                session.add(new_folder)
                                                session.flush()
                                                parent_id = new_folder.id

                                        created_folders[folder_path] = parent_id
                                        session.commit()

                                target_folder_id = created_folders.get(folder_path)

                            # Dokument speichern
                            doc_id = save_document(file_data, filename, user_id)

                            # Ordner zuweisen wenn erstellt
                            if target_folder_id:
                                with get_db() as session:
                                    doc = session.get(Document, doc_id)
                                    if doc:
                                        doc.folder_id = target_folder_id
                                        # Speichere Quellpfad f√ºr sp√§tere Analyse
                                        doc.notes = f"Importiert aus: {folder_path}"
                                        session.commit()

                            # OCR verarbeiten wenn gew√ºnscht
                            if process_docs:
                                try:
                                    process_document(doc_id, file_data, user_id)
                                except Exception as proc_err:
                                    st.toast(f"‚ö†Ô∏è Verarbeitung: {str(proc_err)[:50]}")

                            imported_count += 1

                        except Exception as e:
                            error_count += 1
                            st.warning(f"‚ö†Ô∏è Fehler bei {filename}: {str(e)[:100]}")

                    progress_bar.progress(1.0, text="‚úÖ Import abgeschlossen!")
                    status_text.empty()

                    # Ergebnis
                    st.success(f"‚úÖ **{imported_count} Dokumente erfolgreich importiert!**")
                    if created_folders:
                        st.info(f"üìÅ **{len(created_folders)} Ordner** wurden erstellt")
                    if error_count > 0:
                        st.warning(f"‚ö†Ô∏è {error_count} Fehler beim Import")

        except zipfile.BadZipFile:
            st.error("‚ùå Ung√ºltige ZIP-Datei. Bitte pr√ºfen Sie das Archiv.")
        except Exception as e:
            st.error(f"‚ùå Fehler beim Lesen der ZIP-Datei: {e}")

    # Option 2: Mehrere Dateien per Drag & Drop
    st.markdown("---")
    st.markdown("### üìé Option 2: Mehrere Dateien hochladen")
    st.info("üí° W√§hlen Sie mehrere Dateien aus einem Ordner aus (Strg+A zum Ausw√§hlen aller Dateien)")

    multi_files = st.file_uploader(
        "Dateien ausw√§hlen (Mehrfachauswahl m√∂glich)",
        type=['pdf', 'jpg', 'jpeg', 'png', 'gif', 'doc', 'docx', 'xls', 'xlsx', 'txt'],
        accept_multiple_files=True,
        key="folder_multi_upload",
        help="Halten Sie Strg/Cmd gedr√ºckt um mehrere Dateien auszuw√§hlen"
    )

    if multi_files and len(multi_files) > 0:
        st.success(f"‚úÖ **{len(multi_files)} Dateien** ausgew√§hlt")

        user_id = get_current_user_id()

        # Zielordner ausw√§hlen
        with get_db() as session:
            folders = session.query(Folder).filter(
                Folder.user_id == user_id
            ).order_by(Folder.name).all()
            folder_options = {f.id: f.name for f in folders}
            folder_options[None] = "üì• Posteingang"

        target_folder = st.selectbox(
            "Zielordner",
            options=list(folder_options.keys()),
            format_func=lambda x: folder_options.get(x, "Posteingang"),
            key="multi_target_folder"
        )

        process_multi = st.checkbox("Dokumente sofort verarbeiten (OCR)", value=True, key="process_multi_files")

        if st.button("üì• Alle Dateien importieren", type="primary", key="import_multi"):
            progress_bar = st.progress(0, text="Starte Import...")

            imported = 0
            for idx, file in enumerate(multi_files):
                progress_bar.progress((idx + 1) / len(multi_files), text=f"Importiere {file.name}...")

                try:
                    file_data = file.read()
                    doc_id = save_document(file_data, file.name, user_id)

                    # Zielordner setzen
                    if target_folder:
                        with get_db() as session:
                            doc = session.get(Document, doc_id)
                            if doc:
                                doc.folder_id = target_folder
                                session.commit()

                    # Verarbeiten
                    if process_multi:
                        try:
                            process_document(doc_id, file_data, user_id)
                        except Exception as proc_err:
                            st.toast(f"‚ö†Ô∏è Verarbeitung von {file.name}: {str(proc_err)[:50]}")

                    imported += 1
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Fehler bei {file.name}: {str(e)[:100]}")

            progress_bar.progress(1.0, text="‚úÖ Fertig!")
            st.success(f"‚úÖ **{imported} Dateien** erfolgreich importiert!")


with tab_cloud:
    st.subheader("‚òÅÔ∏è Cloud-Import")
    st.markdown("Importieren Sie Dokumente direkt aus Dropbox oder Google Drive.")

    # Import Cloud-Sync Service
    try:
        from services.cloud_sync_service import CloudSyncService, CloudProvider, SyncStatus
        CLOUD_IMPORT_AVAILABLE = True
    except ImportError:
        CLOUD_IMPORT_AVAILABLE = False

    if not CLOUD_IMPORT_AVAILABLE:
        st.error("Cloud-Import Module nicht verf√ºgbar.")
    else:
        user_id = get_current_user_id()
        cloud_service = CloudSyncService(user_id)

        # Aktive Sync-Verbindungen anzeigen
        connections = cloud_service.get_connections()
        active_connections = [c for c in connections if c.is_active]

        if active_connections:
            st.markdown("### üîó Gespeicherte Cloud-Verbindungen")

            for conn in active_connections:
                provider_icon = "üì¶" if conn.provider == CloudProvider.DROPBOX else "üîµ"
                provider_name = "Dropbox" if conn.provider == CloudProvider.DROPBOX else "Google Drive"

                col_info, col_actions = st.columns([3, 1])

                with col_info:
                    interval_text = f" (alle {conn.sync_interval_minutes} Min.)" if conn.sync_interval_minutes else " (einmalig)"
                    folder_display = conn.folder_path or conn.folder_id or "Unbekannt"
                    # K√ºrze lange URLs
                    if len(folder_display) > 60:
                        folder_display = folder_display[:57] + "..."
                    st.info(f"{provider_icon} **{provider_name}**{interval_text}\n\n`{folder_display}`")

                with col_actions:
                    if st.button("üóëÔ∏è L√∂schen", key=f"delete_conn_{conn.id}", help="Verbindung l√∂schen"):
                        cloud_service.delete_connection(conn.id)
                        st.success("Verbindung gel√∂scht!")
                        st.rerun()

            st.markdown("---")

        # Schnell-Import Formular
        st.markdown("### üì• Schnell-Import aus Cloud-Ordner")

        col1, col2 = st.columns([2, 1])

        with col1:
            cloud_link = st.text_input(
                "Cloud-Link einf√ºgen",
                placeholder="https://www.dropbox.com/scl/fo/... oder https://drive.google.com/drive/folders/...",
                help="F√ºgen Sie hier den Link zu einem Dropbox- oder Google Drive-Ordner ein"
            )

        with col2:
            # Automatische Erkennung des Providers
            detected_provider = None
            if cloud_link:
                if "dropbox.com" in cloud_link.lower():
                    detected_provider = "dropbox"
                    st.success("üì¶ Dropbox erkannt")
                elif "drive.google.com" in cloud_link.lower():
                    detected_provider = "google_drive"
                    st.success("üîµ Google Drive erkannt")
                else:
                    st.warning("‚ö†Ô∏è Unbekannter Link")

        # Sync-Optionen
        st.markdown("#### Sync-Optionen")
        col_opt1, col_opt2 = st.columns(2)

        with col_opt1:
            import_mode = st.radio(
                "Import-Modus",
                options=["once", "interval", "continuous"],
                format_func=lambda x: {
                    "once": "üîÇ Einmalig - Nur jetzt importieren",
                    "interval": "‚è±Ô∏è Intervall - Regelm√§√üig synchronisieren",
                    "continuous": "‚ôæÔ∏è Dauerhaft - Bis ich stoppe"
                }.get(x),
                horizontal=False
            )

        with col_opt2:
            if import_mode == "interval":
                sync_interval = st.selectbox(
                    "Sync-Intervall",
                    options=[5, 15, 30, 60, 120, 360, 720, 1440],
                    format_func=lambda x: {
                        5: "Alle 5 Minuten",
                        15: "Alle 15 Minuten",
                        30: "Alle 30 Minuten",
                        60: "Jede Stunde",
                        120: "Alle 2 Stunden",
                        360: "Alle 6 Stunden",
                        720: "Alle 12 Stunden",
                        1440: "T√§glich"
                    }.get(x),
                    index=2
                )
            elif import_mode == "continuous":
                st.info("‚ôæÔ∏è Dauerhaft: Ordner wird kontinuierlich √ºberwacht (alle 5 Min.)")
                sync_interval = 5
            else:
                st.info("üîÇ Einmalig: Dateien werden nur jetzt importiert")
                sync_interval = None

        # Hilfsfunktion f√ºr Zeitformatierung
        def format_time(seconds):
            """Formatiert Sekunden als lesbare Zeit"""
            if seconds is None or seconds < 0:
                return "Berechne..."
            if seconds < 60:
                return f"{int(seconds)} Sek."
            elif seconds < 3600:
                mins = int(seconds / 60)
                secs = int(seconds % 60)
                return f"{mins} Min. {secs} Sek."
            else:
                hours = int(seconds / 3600)
                mins = int((seconds % 3600) / 60)
                return f"{hours} Std. {mins} Min."

        def format_file_size(bytes_size):
            """Formatiert Bytes als lesbare Gr√∂√üe"""
            if bytes_size < 1024:
                return f"{bytes_size} B"
            elif bytes_size < 1024 * 1024:
                return f"{bytes_size / 1024:.1f} KB"
            else:
                return f"{bytes_size / (1024 * 1024):.1f} MB"

        # Buttons nebeneinander
        col_import, col_diagnose = st.columns([2, 1])

        with col_import:
            import_clicked = st.button("‚òÅÔ∏è Import starten", type="primary", disabled=not cloud_link or not detected_provider)

        with col_diagnose:
            diagnose_clicked = st.button("üîç Diagnose", disabled=not cloud_link or detected_provider != "google_drive",
                                         help="Zeigt Details zum Google Drive Ordner")

        # Diagnose-Funktion
        if diagnose_clicked and cloud_link and detected_provider == "google_drive":
            import requests
            import re
            from config.settings import get_api_key

            # Folder-ID extrahieren
            folder_id = None
            for pattern in [r'folders/([a-zA-Z0-9_-]+)', r'id=([a-zA-Z0-9_-]+)']:
                match = re.search(pattern, cloud_link)
                if match:
                    folder_id = match.group(1)
                    break

            if folder_id:
                st.markdown("---")
                st.subheader("üîç Google Drive Diagnose")
                st.code(f"Folder-ID: {folder_id}")

                # ========== API TEST ==========
                api_key = get_api_key('GOOGLE_API_KEY')
                if api_key:
                    st.markdown("### üîë Google Drive API Test")
                    st.success(f"API Key gefunden: `{api_key[:10]}...`")

                    with st.spinner("Teste Google Drive API..."):
                        try:
                            BASE = "https://www.googleapis.com/drive/v3/files"
                            params = {
                                "q": f"'{folder_id}' in parents and trashed=false",
                                "fields": "files(id,name,mimeType,size)",
                                "pageSize": 100,
                                "key": api_key,
                            }
                            api_response = requests.get(BASE, params=params, timeout=30)

                            st.markdown(f"**API Status:** {api_response.status_code}")

                            if api_response.status_code == 200:
                                data = api_response.json()
                                files = data.get("files", [])
                                st.success(f"‚úÖ API funktioniert! {len(files)} Eintr√§ge gefunden")

                                if files:
                                    folders = [f for f in files if f.get('mimeType') == 'application/vnd.google-apps.folder']
                                    docs = [f for f in files if f.get('mimeType') != 'application/vnd.google-apps.folder']

                                    st.markdown(f"**Ordner:** {len(folders)} | **Dateien:** {len(docs)}")

                                    with st.expander(f"üìã API-Ergebnisse ({len(files)} Eintr√§ge)", expanded=True):
                                        for f in files[:20]:
                                            mime = f.get('mimeType', '')
                                            icon = "üìÅ" if 'folder' in mime else "üìÑ"
                                            st.write(f"{icon} {f.get('name')} (`{mime[:30]}`)")
                                        if len(files) > 20:
                                            st.caption(f"... und {len(files) - 20} weitere")

                                    # Test Unterordner
                                    if folders:
                                        st.markdown("### üìÇ Test Unterordner-Zugriff")
                                        test_folder = folders[0]
                                        st.markdown(f"Teste Zugriff auf: **{test_folder.get('name')}**")

                                        subfolder_params = {
                                            "q": f"'{test_folder.get('id')}' in parents and trashed=false",
                                            "fields": "files(id,name,mimeType)",
                                            "pageSize": 50,
                                            "key": api_key,
                                        }
                                        sub_response = requests.get(BASE, params=subfolder_params, timeout=30)

                                        if sub_response.status_code == 200:
                                            sub_data = sub_response.json()
                                            sub_files = sub_data.get("files", [])
                                            st.success(f"‚úÖ Unterordner-Zugriff OK! {len(sub_files)} Eintr√§ge in '{test_folder.get('name')}'")

                                            if sub_files:
                                                with st.expander(f"Inhalt von '{test_folder.get('name')}'"):
                                                    for sf in sub_files[:10]:
                                                        mime = sf.get('mimeType', '')
                                                        icon = "üìÅ" if 'folder' in mime else "üìÑ"
                                                        st.write(f"{icon} {sf.get('name')}")
                                            else:
                                                st.info("Unterordner ist leer oder enth√§lt nur Google Docs")
                                        else:
                                            st.error(f"‚ùå Unterordner-Zugriff fehlgeschlagen: {sub_response.status_code}")
                                            st.code(sub_response.text[:500])
                                else:
                                    st.warning("Ordner ist leer oder API hat keine Berechtigung")

                            elif api_response.status_code == 404:
                                st.error("‚ùå **404 - Ordner nicht gefunden**")
                                st.markdown("""
                                **M√∂gliche Ursachen:**
                                1. Der Ordner ist nicht mit "Jeder mit dem Link" geteilt
                                2. Die Google Drive API ist nicht aktiviert
                                3. Der API Key hat keine Berechtigung

                                **L√∂sung:** √ñffnen Sie den Ordner in Google Drive ‚Üí Rechtsklick ‚Üí Freigeben ‚Üí "Jeder mit dem Link" ‚Üí "Betrachter"
                                """)
                            elif api_response.status_code == 403:
                                st.error("‚ùå **403 - Zugriff verweigert**")
                                st.code(api_response.text[:500])
                            else:
                                st.error(f"‚ùå API Fehler: {api_response.status_code}")
                                st.code(api_response.text[:500])

                        except Exception as e:
                            st.error(f"API Fehler: {e}")
                else:
                    st.warning("‚ö†Ô∏è Kein Google API Key in Streamlit Secrets gefunden")
                    st.markdown("Bitte `GOOGLE_API_KEY` in Streamlit Secrets hinterlegen")

                st.markdown("---")
                st.markdown("### üåê Web-Scraping Fallback")

                with st.spinner("Lade Ordner-Inhalt..."):
                    try:
                        headers = {
                            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                        }

                        # Standard-URL
                        url = f"https://drive.google.com/drive/folders/{folder_id}"
                        response = requests.get(url, headers=headers, timeout=30, allow_redirects=True)

                        st.markdown(f"**HTTP Status:** {response.status_code}")
                        st.markdown(f"**Finale URL:** `{response.url[:80]}...`")
                        st.markdown(f"**HTML L√§nge:** {len(response.text)} Zeichen")

                        html = response.text
                        html_lower = html.lower()

                        # Zugriffspr√ºfung
                        if 'accounts.google.com' in response.url:
                            st.error("‚ùå **Problem:** Weiterleitung zur Anmeldung - Ordner ist NICHT √∂ffentlich!")
                        elif 'you need access' in html_lower:
                            st.error("‚ùå **Problem:** Zugriff verweigert!")
                        else:
                            st.success("‚úì Ordner scheint zug√§nglich")

                        # Dateien suchen mit verbesserten Methoden
                        st.markdown("**Suche nach Dateien/Ordnern:**")

                        found_items = []
                        seen_ids = set()

                        def is_valid_name(name):
                            """Pr√ºft ob ein Name ein g√ºltiger Datei/Ordnername ist"""
                            if not name or len(name) < 2 or len(name) > 200:
                                return False
                            # Filtere URLs, JS-Code und System-Strings
                            invalid = ['http', 'https', 'clients', '.com', '.google',
                                       'sign in', 'anmelden', 'null', 'undefined',
                                       'function', 'return', 'var ', 'const ', 'window.',
                                       '();', '{}', 'prototype', 'throw', 'catch']
                            name_lower = name.lower()
                            if any(inv in name_lower for inv in invalid):
                                return False
                            # Muss mindestens einen Buchstaben enthalten
                            if not re.search(r'[a-zA-Z√§√∂√º√Ñ√ñ√ú√ü]', name):
                                return False
                            return True

                        # Methode 1: Suche nach Dateinamen mit Erweiterungen
                        # Flexibleres Pattern: ID gefolgt von Name mit Erweiterung
                        ext_pattern = r'"([a-zA-Z0-9_-]{20,})"[,\]\[null"]*"([^"]+\.(?:pdf|jpg|jpeg|png|gif|doc|docx|xls|xlsx|ppt|pptx|txt|csv|zip|PDF|JPG|PNG|DOC|XLS))"'
                        for fid, name in re.findall(ext_pattern, html):
                            if fid not in seen_ids and is_valid_name(name):
                                seen_ids.add(fid)
                                found_items.append((fid, name, "üìÑ"))

                        # Methode 2: Name mit Erweiterung gefolgt von ID
                        rev_pattern = r'"([^"]+\.(?:pdf|jpg|jpeg|png|doc|docx|xls|xlsx|txt|PDF|JPG|PNG))"[,\]\[null"]*"([a-zA-Z0-9_-]{20,})"'
                        for name, fid in re.findall(rev_pattern, html):
                            if fid not in seen_ids and is_valid_name(name):
                                seen_ids.add(fid)
                                found_items.append((fid, name, "üìÑ"))

                        # Methode 3: Suche alle .pdf Erw√§hnungen ZUERST (vor Ordnern)
                        pdf_names = re.findall(r'"([^"]{3,80}\.pdf)"', html, re.IGNORECASE)
                        for name in pdf_names:
                            if is_valid_name(name) and name not in [f[1] for f in found_items]:
                                # Suche ID in der N√§he
                                idx = html.find(f'"{name}"')
                                if idx >= 0:
                                    context = html[max(0,idx-150):idx+150]
                                    id_match = re.search(r'"([a-zA-Z0-9_-]{25,})"', context)
                                    if id_match:
                                        fid = id_match.group(1)
                                        if fid not in seen_ids:
                                            seen_ids.add(fid)
                                            found_items.append((fid, name, "üìÑ"))

                        # Methode 4: Alle Ordner-IDs aus /folders/ Links
                        folder_ids_found = set(re.findall(r'/folders/([a-zA-Z0-9_-]{20,})', html))
                        folder_ids_found.discard(folder_id)
                        for fid in folder_ids_found:
                            if fid not in seen_ids:
                                # Suche Namen in der N√§he der ID
                                idx = html.find(fid)
                                if idx >= 0:
                                    context = html[max(0,idx-100):idx+200]
                                    # Suche nach "Name" nach der ID
                                    name_match = re.search(rf'{fid}"[,\]\[null"]*"([^"]+)"', context)
                                    if name_match and is_valid_name(name_match.group(1)):
                                        name = name_match.group(1)
                                        # WICHTIG: Pr√ºfen ob es eine Datei ist (hat Erweiterung)
                                        is_file = bool(re.search(r'\.\w{2,5}$', name))
                                        seen_ids.add(fid)
                                        found_items.append((fid, name, "üìÑ" if is_file else "üìÅ"))
                                    else:
                                        seen_ids.add(fid)
                                        found_items.append((fid, f"Ordner {len(found_items)+1}", "üìÅ"))

                        # Methode 5: data-id Attribute mit aria-label/title in der N√§he
                        for match in re.finditer(r'data-id="([a-zA-Z0-9_-]{20,})"', html):
                            fid = match.group(1)
                            if fid not in seen_ids:
                                # Hole Kontext um das Attribut
                                start = max(0, match.start() - 300)
                                end = min(len(html), match.end() + 300)
                                context = html[start:end]

                                # Suche nach aria-label oder data-tooltip
                                label = re.search(r'(?:aria-label|data-tooltip|title)="([^"]+)"', context)
                                if label and is_valid_name(label.group(1)):
                                    name = label.group(1)
                                    seen_ids.add(fid)
                                    is_file = bool(re.search(r'\.\w{2,5}$', name))
                                    found_items.append((fid, name, "üìÑ" if is_file else "üìÅ"))

                        # Methode 6: Kompakte JSON-Struktur ["ID","Name"]
                        compact_pattern = r'\["([a-zA-Z0-9_-]{25,})",\s*"([^"]{2,100})"'
                        for fid, name in re.findall(compact_pattern, html):
                            if fid not in seen_ids and is_valid_name(name):
                                seen_ids.add(fid)
                                is_file = bool(re.search(r'\.\w{2,5}$', name))
                                found_items.append((fid, name, "üìÑ" if is_file else "üìÅ"))

                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Gefundene Elemente", len(found_items))
                        with col2:
                            files_count = len([f for f in found_items if f[2] == "üìÑ"])
                            folders_count = len([f for f in found_items if f[2] == "üìÅ"])
                            st.metric("Dateien / Ordner", f"{files_count} / {folders_count}")

                        if found_items:
                            with st.expander(f"üìã Gefundene Elemente ({len(found_items)})", expanded=True):
                                for fid, name, icon in found_items[:30]:
                                    st.write(f"{icon} {name}")
                                if len(found_items) > 30:
                                    st.caption(f"... und {len(found_items) - 30} weitere")
                        else:
                            st.warning("‚ö†Ô∏è Keine Dateien/Ordner im HTML gefunden!")
                            st.markdown("""
**M√∂gliche Ursachen:**
1. **Google l√§dt Inhalte mit JavaScript** - nicht direkt im HTML
2. Der Ordner ist leer
3. Das HTML-Format hat sich ge√§ndert

**Empfehlung:** Teilen Sie die Debug-Info unten mit dem Entwickler.
                            """)

                        # Debug-Info
                        with st.expander("üîß Debug-Info", expanded=True):
                            st.markdown("**Gefundene Marker im HTML:**")
                            markers = {
                                "data-id Attribute": len(re.findall(r'data-id="[a-zA-Z0-9_-]{20,}"', html)),
                                "file/d/ Links": len(re.findall(r'/file/d/[a-zA-Z0-9_-]{20,}', html)),
                                "folders/ Links": len(re.findall(r'/folders/[a-zA-Z0-9_-]{20,}', html)),
                                "PDF im Text": html.lower().count('.pdf'),
                                "Ordner-ID im HTML": html.count(folder_id),
                            }
                            for marker, count in markers.items():
                                st.write(f"- {marker}: {count}")

                            # Zeige was jede Methode findet
                            st.markdown("---")
                            st.markdown("**Details pro Methode:**")

                            # Methode 1 Debug
                            m1_results = re.findall(r'"([a-zA-Z0-9_-]{20,})"[,\]\[null"]*"([^"]+\.(?:pdf|jpg|jpeg|png|gif|doc|docx|xls|xlsx|ppt|pptx|txt|csv|zip|PDF|JPG|PNG|DOC|XLS))"', html)
                            st.write(f"Methode 1 (ID‚ÜíDatei): {len(m1_results)} Treffer")
                            if m1_results[:3]:
                                for fid, name in m1_results[:3]:
                                    st.code(f"  {fid[:15]}... ‚Üí {name}")

                            # Methode 2 Debug
                            m2_results = re.findall(r'"([^"]+\.(?:pdf|jpg|jpeg|png|doc|docx|xls|xlsx|txt|PDF|JPG|PNG))"[,\]\[null"]*"([a-zA-Z0-9_-]{20,})"', html)
                            st.write(f"Methode 2 (Datei‚ÜíID): {len(m2_results)} Treffer")
                            if m2_results[:3]:
                                for name, fid in m2_results[:3]:
                                    st.code(f"  {name} ‚Üí {fid[:15]}...")

                            # Methode 3 Debug - PDFs
                            m3_results = re.findall(r'"([^"]{3,80}\.pdf)"', html, re.IGNORECASE)
                            st.write(f"Methode 3 (PDF-Namen): {len(m3_results)} Treffer")
                            valid_pdfs = [n for n in m3_results if is_valid_name(n)]
                            st.write(f"  Davon g√ºltig: {len(valid_pdfs)}")
                            if valid_pdfs[:5]:
                                for name in valid_pdfs[:5]:
                                    st.code(f"  üìÑ {name}")

                            # Methode 4 Debug - Ordner
                            m4_results = set(re.findall(r'/folders/([a-zA-Z0-9_-]{20,})', html))
                            m4_results.discard(folder_id)
                            st.write(f"Methode 4 (/folders/ Links): {len(m4_results)} Ordner-IDs")

                            # Zeige Ordnernamen die gefunden werden
                            folder_names_found = []
                            for fid in list(m4_results)[:5]:
                                idx = html.find(fid)
                                if idx >= 0:
                                    context = html[max(0,idx-100):idx+200]
                                    name_match = re.search(rf'{fid}"[,\]\[null"]*"([^"]+)"', context)
                                    if name_match:
                                        folder_names_found.append((fid[:15], name_match.group(1)))
                            if folder_names_found:
                                for fid, name in folder_names_found:
                                    is_file = bool(re.search(r'\.\w{2,5}$', name))
                                    icon = "üìÑ" if is_file else "üìÅ"
                                    valid = "‚úì" if is_valid_name(name) else "‚úó"
                                    st.code(f"  {icon} {valid} {fid}... ‚Üí {name}")

                            # Zeige Beispiel-Datenstruktur
                            st.markdown("---")
                            st.markdown("**Suche nach JSON-Daten im HTML:**")

                            # Suche nach typischen Google Drive Datenstrukturen
                            # Google verwendet oft Arrays wie: ["ID","Titel",null,null,...]
                            json_arrays = re.findall(r'\["([a-zA-Z0-9_-]{25,})","([^"]{2,60})"', html)
                            st.write(f'JSON-Arrays ["ID","Name"]: {len(json_arrays)} gefunden')

                            # Filtere g√ºltige Namen
                            valid_arrays = [(fid, name) for fid, name in json_arrays if is_valid_name(name)]
                            st.write(f"Davon mit g√ºltigen Namen: {len(valid_arrays)}")
                            if valid_arrays[:5]:
                                for fid, name in valid_arrays[:5]:
                                    is_file = bool(re.search(r'\.\w{2,5}$', name))
                                    st.code(f"  {'üìÑ' if is_file else 'üìÅ'} {name}")

                            st.markdown("---")
                            st.markdown("**Erste 4000 Zeichen des HTML:**")
                            st.code(html[:4000])

                    except Exception as e:
                        st.error(f"Fehler: {e}")

        # Import starten
        if import_clicked:
            if cloud_link and detected_provider:
                try:
                    # Verbindung erstellen
                    conn = cloud_service.create_connection(
                        provider=CloudProvider.DROPBOX if detected_provider == "dropbox" else CloudProvider.GOOGLE_DRIVE,
                        folder_id=cloud_link,
                        folder_path=cloud_link,
                        sync_interval_minutes=sync_interval
                    )

                    st.success("‚úÖ Cloud-Verbindung erstellt!")

                    # Fortschrittsanzeige
                    progress_container = st.container()

                    with progress_container:
                        progress_bar = st.progress(0, text="Initialisiere...")
                        status_container = st.empty()
                        file_info_container = st.empty()
                        step_detail_container = st.empty()  # NEU: Detaillierte Schritte
                        stats_container = st.empty()

                        # Synchronisieren mit Fortschrittsanzeige
                        final_result = None
                        for progress in cloud_service.sync_connection_with_progress(conn.id):
                            final_result = progress
                            phase = progress.get("phase", "")

                            # Fortschrittsbalken aktualisieren
                            percent = progress.get("progress_percent", 0)
                            progress_bar.progress(percent / 100)

                            # Status-Text
                            if phase == "initializing":
                                status_container.info("üîÑ Initialisiere Verbindung...")
                                step_detail_container.markdown("*Verbindung wird hergestellt...*")
                            elif phase == "scanning":
                                status_container.info("üîç **Scanne Cloud-Ordner nach Dateien...**")
                                step_detail_container.markdown(
                                    "‚è≥ *Durchsuche Ordner und Unterordner... Dies kann einen Moment dauern.*"
                                )
                            elif phase == "downloading":
                                files_total = progress.get("files_total", 0)
                                files_processed = progress.get("files_processed", 0)
                                elapsed = progress.get("elapsed_seconds", 0)
                                remaining = progress.get("estimated_remaining_seconds")

                                time_info = f"‚è±Ô∏è Verstrichene Zeit: {format_time(elapsed)}"
                                if remaining is not None and remaining > 0:
                                    time_info += f" | ‚è≥ Restzeit: ~{format_time(remaining)}"

                                status_container.info(
                                    f"üì• Importiere Dateien: {files_processed + 1} von {files_total}\n\n{time_info}"
                                )

                                # Aktuelle Datei anzeigen
                                current_file = progress.get("current_file")
                                current_size = progress.get("current_file_size", 0)
                                source_folder = progress.get("source_folder", "")
                                if current_file:
                                    folder_info = f" (aus `{source_folder}`)" if source_folder else ""
                                    file_info_container.markdown(
                                        f"üìÑ **Aktuelle Datei:** `{current_file}` ({format_file_size(current_size)}){folder_info}"
                                    )

                                # Detaillierter Verarbeitungsschritt anzeigen
                                current_step_detail = progress.get("current_step_detail", "")
                                if current_step_detail:
                                    step_detail_container.markdown(f"**Aktion:** {current_step_detail}")
                                else:
                                    step_detail_container.empty()

                                # Statistiken
                                synced = progress.get("files_synced", 0)
                                skipped = progress.get("files_skipped", 0)
                                errors = progress.get("files_error", 0)
                                stats_container.caption(
                                    f"‚úÖ Importiert: {synced} | ‚è≠Ô∏è √úbersprungen: {skipped} | ‚ùå Fehler: {errors}"
                                )

                            elif phase == "completed":
                                progress_bar.progress(1.0, text="‚úÖ Abgeschlossen!")
                                status_container.success(
                                    f"‚úÖ **Synchronisation abgeschlossen!**\n\n"
                                    f"‚è±Ô∏è Gesamtzeit: {format_time(progress.get('elapsed_seconds', 0))}"
                                )
                                step_detail_container.empty()
                            elif phase == "error":
                                progress_bar.progress(0, text="‚ùå Fehler")
                                status_container.error(f"‚ùå Fehler: {progress.get('error', 'Unbekannt')}")
                                step_detail_container.empty()

                        # Endergebnis verarbeiten
                        file_info_container.empty()
                        step_detail_container.empty()

                        if final_result:
                            new_files = final_result.get("new_files", 0)
                            skipped = final_result.get("skipped_files", 0)
                            synced_files = final_result.get("synced_files", [])

                            if new_files > 0:
                                st.success(f"‚úÖ **{new_files} Dateien erfolgreich importiert!**")

                                # Importierte Dateien auflisten
                                if synced_files:
                                    with st.expander(f"üìã Importierte Dateien ({len(synced_files)})", expanded=False):
                                        for fname in synced_files:
                                            st.write(f"‚Ä¢ {fname}")

                                st.info(f"üìÅ Dateien wurden im Posteingang abgelegt.")

                                # Hinweis auf Verarbeitung
                                st.markdown("---")
                                st.markdown("### üìã N√§chste Schritte")
                                st.write("1. Gehen Sie zum Tab **'‚öôÔ∏è Verarbeitung'** um die importierten Dokumente zu verarbeiten")
                                st.write("2. Oder besuchen Sie **'üìÅ Dokumente'** um die neuen Dokumente zu sehen")

                            elif final_result.get("files_total", 0) == 0:
                                st.warning("üì≠ **Keine Dateien gefunden!**")

                                # Zeige den verwendeten Link zur Kontrolle
                                st.markdown(f"**Verwendeter Link:** `{cloud_link}`")

                                # Debug-Info zur Verbindung
                                with st.expander("üîß Verbindungs-Details", expanded=True):
                                    st.code(f"""Connection ID: {conn.id}
Provider: {conn.provider}
Remote Folder ID: {conn.folder_id}
Remote Folder Path: {conn.folder_path}
Is Active: {conn.is_active}
File Extensions: {conn.file_extensions}""")

                                # Hilfreiche Tipps anzeigen
                                with st.expander("üîç M√∂gliche Ursachen & L√∂sungen", expanded=True):
                                    st.markdown("""
**1. Ordner ist nicht √∂ffentlich freigegeben:**
   - √ñffnen Sie den Ordner in Google Drive
   - Rechtsklick ‚Üí **Freigeben**
   - Klicken Sie auf "Zugriff beschr√§nkt" ‚Üí **"Jeder mit dem Link"**
   - Stellen Sie sicher, dass "Betrachter" ausgew√§hlt ist

**2. Link ist falsch:**
   - Der Link muss auf einen **Ordner** zeigen (nicht auf eine einzelne Datei)
   - Format: `https://drive.google.com/drive/folders/ORDNER_ID`

**3. Ordner ist leer:**
   - Pr√ºfen Sie, ob der Ordner tats√§chlich Dateien enth√§lt

**4. Unterst√ºtzte Dateitypen:**
   - PDF, JPG, JPEG, PNG, GIF, DOC, DOCX, XLS, XLSX, TXT

**5. Google Drive Format-√Ñnderung:**
   - Google √§ndert manchmal das HTML-Format
   - Pr√ºfen Sie die Debug-Datei unter `data/debug/` f√ºr Details
                                    """)

                                # Button zum Testen des Links
                                st.markdown(f"[üîó Link im Browser √∂ffnen]({cloud_link})")

                                # Debug-Informationen anzeigen
                                from pathlib import Path
                                debug_path = Path("data/debug")
                                if debug_path.exists():
                                    debug_files = list(debug_path.glob("gdrive_debug_*.html"))
                                    if debug_files:
                                        with st.expander("üîß Debug-Informationen (f√ºr Entwickler)", expanded=False):
                                            st.markdown("Eine Debug-Datei wurde erstellt. Diese kann helfen, das Problem zu analysieren:")
                                            for df in sorted(debug_files, key=lambda x: x.stat().st_mtime, reverse=True)[:3]:
                                                st.code(f"{df.name} ({df.stat().st_size / 1024:.1f} KB)")

                            if skipped > 0:
                                st.caption(f"‚ÑπÔ∏è {skipped} Dateien √ºbersprungen (bereits vorhanden oder nicht unterst√ºtzt)")

                            if final_result.get("error") and not final_result.get("success"):
                                error_msg = final_result.get("error", "Unbekannter Fehler")
                                if "token" in error_msg.lower() or "auth" in error_msg.lower():
                                    st.warning(f"‚ö†Ô∏è API-Authentifizierung erforderlich. Bitte konfigurieren Sie Ihre Cloud-API unter **Einstellungen ‚Üí Cloud-Sync**.")
                                else:
                                    st.error(f"‚ùå Import fehlgeschlagen: {error_msg}")

                    # Bei einmaligem Import Verbindung deaktivieren
                    if import_mode == "once":
                        cloud_service.delete_connection(conn.id)
                        st.caption("‚ÑπÔ∏è Einmaliger Import abgeschlossen. Verbindung wurde entfernt.")
                    else:
                        st.info(f"üîÑ Dauerhafte Sync eingerichtet. Verwalten unter **Einstellungen ‚Üí Cloud-Sync**.")

                except Exception as e:
                    st.error(f"Fehler beim Import: {e}")
            else:
                st.error("Bitte geben Sie einen g√ºltigen Cloud-Link ein.")

        # Hinweis auf Einstellungen
        st.markdown("---")
        st.caption("üí° **Tipp:** F√ºr erweiterte Cloud-Sync Optionen und API-Konfiguration besuchen Sie **Einstellungen ‚Üí Cloud-Sync**.")


with tab_process:
    st.subheader("Unverarbeitete Dokumente")

    user_id = get_current_user_id()

    with get_db() as session:
        pending_docs = session.query(Document).filter(
            Document.user_id == user_id,
            Document.status.in_([DocumentStatus.PENDING, DocumentStatus.ERROR])
        ).all()

        if pending_docs:
            st.info(f"{len(pending_docs)} Dokumente warten auf Verarbeitung")

            for doc in pending_docs:
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    status_icon = "‚è≥" if doc.status == DocumentStatus.PENDING else "‚ùå"
                    st.write(f"{status_icon} {doc.filename}")
                    if doc.processing_error:
                        st.caption(f"Fehler: {doc.processing_error}")
                with col2:
                    st.caption(format_date(doc.created_at))
                with col3:
                    if st.button("Verarbeiten", key=f"process_{doc.id}"):
                        # Datei entschl√ºsseln
                        encryption = get_encryption_service()
                        with open(doc.file_path, 'rb') as f:
                            encrypted_data = f.read()
                        file_data = encryption.decrypt_file(encrypted_data, doc.encryption_iv, doc.filename)

                        with st.spinner("Verarbeite..."):
                            try:
                                process_document(doc.id, file_data, user_id)
                                st.success("Erfolgreich!")
                                st.rerun()
                            except Exception as e:
                                st.error(f"Fehler: {e}")

            if st.button("Alle verarbeiten", type="primary"):
                progress = st.progress(0)
                for i, doc in enumerate(pending_docs):
                    progress.progress((i + 1) / len(pending_docs))
                    encryption = get_encryption_service()
                    with open(doc.file_path, 'rb') as f:
                        encrypted_data = f.read()
                    file_data = encryption.decrypt_file(encrypted_data, doc.encryption_iv, doc.filename)

                    try:
                        process_document(doc.id, file_data, user_id)
                    except:
                        pass
                st.success("Verarbeitung abgeschlossen!")
                st.rerun()
        else:
            st.success("Keine unverarbeiteten Dokumente")
